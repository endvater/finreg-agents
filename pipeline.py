"""
GwG Audit Pipeline â€“ Hauptorchestrator
FÃ¼hrt die gesamte PrÃ¼fung durch: Ingest â†’ Index â†’ PrÃ¼fen â†’ Bericht

Verwendung:
    python pipeline.py --input ./meine_dokumente --institution "Musterbank AG"

Oder als Python-Modul:
    from pipeline import GwGAuditPipeline
    pipeline = GwGAuditPipeline(input_dir="./docs", institution="Musterbank AG")
    report_paths = pipeline.run()
"""

import argparse
import json
import time
from pathlib import Path
from datetime import datetime

from llama_index.core import VectorStoreIndex, Settings
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.anthropic import Anthropic as AnthropicLLM

from ingestion.ingestor import GwGIngestor
from agents.pruef_agent import GwGPrueferAgent, SektionsergebniS
from reports.bericht_generator import GwGBerichtGenerator


class GwGAuditPipeline:
    """
    VollstÃ¤ndige GwG-SonderprÃ¼fungs-Pipeline.

    Pipeline-Schritte:
    1. Dokumenten-Ingestion (PDF, Excel, Interview, Screenshot, Log)
    2. Vektorindex aufbauen (LlamaIndex)
    3. PrÃ¼fkatalog laden
    4. FÃ¼r jedes PrÃ¼ffeld: RAG â†’ LLM-Bewertung â†’ Befund
    5. PrÃ¼fbericht generieren (JSON + MD + HTML)
    """

    def __init__(
        self,
        input_dir: str,
        institution: str = "PrÃ¼finstitut",
        catalog_path: str = None,
        output_dir: str = "./reports/output",
        model: str = "claude-opus-4-5",
        embedding_model: str = "text-embedding-3-small",
        sektionen_filter: list[str] = None,
        top_k: int = 8,
        verbose: bool = True,
    ):
        self.input_dir = input_dir
        self.institution = institution
        self.output_dir = output_dir
        self.model = model
        self.sektionen_filter = sektionen_filter  # z.B. ["S01", "S02"] fÃ¼r TeilprÃ¼fung
        self.top_k = top_k
        self.verbose = verbose

        # Katalogpfad
        if catalog_path is None:
            catalog_path = Path(__file__).parent / "catalog" / "gwg_catalog.json"
        self.catalog_path = catalog_path

        # LlamaIndex-Einstellungen
        Settings.embed_model = OpenAIEmbedding(model=embedding_model)
        Settings.llm = AnthropicLLM(model=model)

    def run(self) -> dict[str, str]:
        """FÃ¼hrt die komplette Pipeline aus. Gibt Pfade zu den Berichten zurÃ¼ck."""
        t_start = time.time()
        self._log("ğŸš€ GwG-SonderprÃ¼fungs-Pipeline gestartet")
        self._log(f"   Institut: {self.institution}")
        self._log(f"   Eingabeverzeichnis: {self.input_dir}")
        self._log("")

        # â”€â”€ Schritt 1: Ingestion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._log("ğŸ“‚ Schritt 1/4: Dokumenten-Ingestion")
        ingestor = GwGIngestor()
        documents = ingestor.ingest_directory(self.input_dir)
        self._log(f"   â†’ {len(documents)} Dokument-Chunks geladen")

        if not documents:
            raise ValueError(
                f"Keine Dokumente in '{self.input_dir}' gefunden. "
                "Bitte Unterordner pdfs/, excel/, interviews/, screenshots/, logs/ prÃ¼fen."
            )

        # â”€â”€ Schritt 2: Vektorindex â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._log("\nğŸ” Schritt 2/4: Vektorindex aufbauen")
        index = VectorStoreIndex.from_documents(documents, show_progress=self.verbose)
        self._log("   â†’ Index fertig")

        # â”€â”€ Schritt 3: PrÃ¼fkatalog laden â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._log("\nğŸ“‹ Schritt 3/4: PrÃ¼fkatalog laden & PrÃ¼fung durchfÃ¼hren")
        katalog = json.loads(Path(self.catalog_path).read_text(encoding="utf-8"))
        agent = GwGPrueferAgent(index=index, model=self.model, top_k=self.top_k)

        sektionsergebnisse = []
        total_felder = 0
        gepruefte_felder = 0

        for sektion in katalog["pruefsektionen"]:
            # Optionaler Filter fÃ¼r TeilprÃ¼fungen
            if self.sektionen_filter and sektion["id"] not in self.sektionen_filter:
                continue

            self._log(f"\n  ğŸ“Œ {sektion['id']}: {sektion['titel']}")
            ergebnis = SektionsergebniS(sektion_id=sektion["id"], titel=sektion["titel"])

            for prueffeld in sektion["prueffelder"]:
                # Rechtsgrundlagen in Prueffeld einbetten (fÃ¼r den Agent)
                prueffeld["rechtsgrundlagen"] = sektion.get("rechtsgrundlagen", [])
                total_felder += 1

                self._log(f"    [{prueffeld['id']}] {prueffeld['frage'][:80]}...")
                t0 = time.time()
                befund = agent.pruefe_feld(prueffeld)
                dauer = time.time() - t0

                status_icon = {
                    "konform": "âœ…", "teilkonform": "âš ï¸",
                    "nicht_konform": "ğŸ”´", "nicht_prÃ¼fbar": "â“"
                }.get(befund.bewertung.value, "?")

                self._log(f"       â†’ {status_icon} {befund.bewertung.value.upper()} ({dauer:.1f}s)")
                ergebnis.befunde.append(befund)
                gepruefte_felder += 1

            sektionsergebnisse.append(ergebnis)

        # â”€â”€ Schritt 4: Berichte generieren â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._log(f"\nğŸ“ Schritt 4/4: PrÃ¼fberichte generieren")
        generator = GwGBerichtGenerator(
            institution=self.institution,
            pruefer="GwG KI-PrÃ¼fungssystem v1.0"
        )
        report_paths = generator.generiere_alle_berichte(
            sektionsergebnisse=sektionsergebnisse,
            output_dir=self.output_dir
        )

        # â”€â”€ Zusammenfassung â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        t_total = time.time() - t_start
        self._log(f"\n{'='*60}")
        self._log(f"âœ… PrÃ¼fung abgeschlossen in {t_total:.0f}s")
        self._log(f"   PrÃ¼ffelder gesamt: {gepruefte_felder}/{total_felder}")
        self._log(f"   Berichte:")
        for fmt, pth in report_paths.items():
            self._log(f"     {fmt.upper()}: {pth}")

        return report_paths

    def _log(self, msg: str):
        if self.verbose:
            print(msg)


# ------------------------------------------------------------------ #
# CLI-Einstiegspunkt
# ------------------------------------------------------------------ #
def main():
    parser = argparse.ArgumentParser(
        description="GwG-SonderprÃ¼fungs-Pipeline (KI-gestÃ¼tzt)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Beispiele:
  # VollstÃ¤ndige PrÃ¼fung
  python pipeline.py --input ./meine_dokumente --institution "Musterbank AG"

  # Nur bestimmte Sektionen prÃ¼fen
  python pipeline.py --input ./docs --sektionen S01 S02 S03

  # Mit eigenem Katalog
  python pipeline.py --input ./docs --catalog ./mein_katalog.json
        """
    )
    parser.add_argument("--input", required=True, help="Verzeichnis mit PrÃ¼fungsdokumenten")
    parser.add_argument("--institution", default="PrÃ¼finstitut", help="Name des Instituts")
    parser.add_argument("--output", default="./reports/output", help="Ausgabeverzeichnis fÃ¼r Berichte")
    parser.add_argument("--catalog", default=None, help="Pfad zum GwG-Katalog JSON")
    parser.add_argument("--model", default="claude-opus-4-5", help="Anthropic-Modell")
    parser.add_argument("--sektionen", nargs="*", help="Nur diese Sektionen prÃ¼fen (z.B. S01 S02)")
    parser.add_argument("--top-k", type=int, default=8, help="Anzahl RAG-Chunks pro PrÃ¼ffrage")
    args = parser.parse_args()

    pipeline = GwGAuditPipeline(
        input_dir=args.input,
        institution=args.institution,
        catalog_path=args.catalog,
        output_dir=args.output,
        model=args.model,
        sektionen_filter=args.sektionen,
        top_k=args.top_k,
    )
    pipeline.run()


if __name__ == "__main__":
    main()
